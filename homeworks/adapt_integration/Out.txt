-------------------------------
PART A - RECURSIVE ADAPTIVE INTEGRATOR
I have implemented the recursive adaptive integrator using the trapezium rule as my higher order rule, and the rectangular rule as my lower.
To test the below integrals, i have used acc = 0.001 and eps = 0.001, and I use these same numbers when comparing my results to the expected values.
I also had to implement a lower limit on h (stepsize), to avoid evaluation of the function in its singularties. This limit is now 1e-9.
Let's test it on some integrals:

Testing ∫_0^1 dx √(x) (should be 2/3) ...
Result: 0.666953909054655, PASSED
with 3 subdivisions and 16 integrand evaluations.

Testing ∫_0^1 dx 1/√(x) (should be 2) ...
Result: 1.9998394321154, PASSED
with 59 subdivisions and 232 integrand evaluations.

Testing ∫_0^1 dx 4√(1-x^2) (should be pi) ...
Result: 3.14183457802727, PASSED
with 6 subdivisions and 28 integrand evaluations.

Testing ∫_0^1 dx ln(x)/√(x) (should be -4) ...
Result: -3.99730382139021, PASSED
with 65 subdivisions and 256 integrand evaluations.

I have implemented the error function in its integral form, and calculated some of its values in erf.txt, and plotted them in the corresponding svg file.
-------------------------------
PART B - OPEN QUADRATURE WITH CLENSHAW-CURTIS
For part B, I had to implement an integral transform. I have constructed a method, which properly transforms the integrand and the limits, and passes this on to my routine from part A.
Let's test it:

Testing ∫_0^1 dx 1/√(x) (should be 2)
Result: 1.99999201046432 +- 0.001187371917641, PASSED
with 3 subdivisions and 16 integrand evaluations.

Testing ∫_0^1 dx ln(x)/√(x) (should be -4)
Result: -3.99987385646141 +- 0.00111272494904313, PASSED
with 23 subdivisions and 96 integrand evaluations.

It is clear that the integral transform significantly lowers the needed amount of operations.
I solved the same two integrals with pythons scipy, which relies on a fortran routine.
It solved ln(x)/sqrt(x) in only eight subdivisions, but with 315 integrand evaluations, and the 1/sqrt(x) integral in 6 subdivisions and 231 integrand evaluations.
It did however find the results with much greater precision, so it would appear, that for now, scipys routine works better, when more difficult integrals must be solved with higher precision.
I tried lowering my tolerance to acc = 1e-08 and rel = 1e-08, but the my routine crashed, even when I set max subdivisions to 20.000... Could it be, that the rules I have used are not optimal for such high precision?
-------------------------------
PART C - ERROR ESTIMATE AND INFINTIE LIMITS
For the first part of c, I made my routine return a tuple with the result and the estimated error. This is the error, I have printed for the evaluations of part b.
The second part of c was to generalise my routine to accept infinite limits. I have implemented this by a series of checks in the beginning of my routine, which transforms the limits and the integrand, in accordance with eqs. (60) - (65) in the material
Let's test it on some convergent integrals:

Testing ∫_0^oo exp(-x) dx (should be 1)
Result: 1.00054304003965 +- 0.00100933256410196, PASSED
with 4 subdivisions and 20 integrand evaluations.

Testing ∫_-oo^oo dx 1/(1+x^2) (should be pi)
Result: 3.14174472820737 +- 0.00102611462612747, PASSED
with 5 subdivisions and 24 integrand evaluations.

 I made scipy solve the same integrals -- It solved 1/(1+x^2) in only one subdivision (30 evaluations), which seems to show, that it must hold some convenient variable transformation, suitable for solving this integral... Or, perhaps, it is just quickly converging. Afterall, my routine solved it in less than 30 evaluations too
For exp(-x), however, scipy needed 3 subdivisions and 75 function evaluations, which can't compete with my routine. However, it acchieves a much more accurate result, even when I manually lower the required accuracy on it.
-------------------------------
